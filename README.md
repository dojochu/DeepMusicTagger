



<!DOCTYPE html>
<html lang="en" class=" is-u2f-enabled">
  <head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# object: http://ogp.me/ns/object# article: http://ogp.me/ns/article# profile: http://ogp.me/ns/profile#">
    <meta charset='utf-8'>
    

    <link crossorigin="anonymous" href="https://assets-cdn.github.com/assets/frameworks-c07e6f4b02b556d1d85052fb3853caf84c80e6b23dcdb1ae1b00f051da1115a2.css" integrity="sha256-wH5vSwK1VtHYUFL7OFPK+EyA5rI9zbGuGwDwUdoRFaI=" media="all" rel="stylesheet" />
    <link crossorigin="anonymous" href="https://assets-cdn.github.com/assets/github-09e1c38d593bf8fc6e4c4f1b526d0184e27c433d64963942c1e8c361589f8125.css" integrity="sha256-CeHDjVk7+PxuTE8bUm0BhOJ8Qz1kljlCwejDYVifgSU=" media="all" rel="stylesheet" />
    
    
    
    

    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="Content-Language" content="en">
    <meta name="viewport" content="width=device-width">
    
    <title>DLA-Interview/README.md at master · dojochu/DLA-Interview</title>
    <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">
    <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <meta property="fb:app_id" content="1401488693436528">

      <meta content="https://avatars1.githubusercontent.com/u/6386581?v=3&amp;s=400" name="twitter:image:src" /><meta content="@github" name="twitter:site" /><meta content="summary" name="twitter:card" /><meta content="dojochu/DLA-Interview" name="twitter:title" /><meta content="Contribute to DLA-Interview development by creating an account on GitHub." name="twitter:description" />
      <meta content="https://avatars1.githubusercontent.com/u/6386581?v=3&amp;s=400" property="og:image" /><meta content="GitHub" property="og:site_name" /><meta content="object" property="og:type" /><meta content="dojochu/DLA-Interview" property="og:title" /><meta content="https://github.com/dojochu/DLA-Interview" property="og:url" /><meta content="Contribute to DLA-Interview development by creating an account on GitHub." property="og:description" />
      <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">
    <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">
    <link rel="assets" href="https://assets-cdn.github.com/">
    <link rel="web-socket" href="wss://live.github.com/_sockets/VjI6MTM5NTY4NzY3OmQyMzcwNTkzNGU0M2M0ZWIyNmY2NzZhOTQ0NzE2ZDVjMTAwMGVmMTdkZDg1NjdlZGJkYjUyZDQzZmFjYWNlNWU=--36147927417b6965ba9efc78c8d46250741b85c5">
    <meta name="pjax-timeout" content="1000">
    <link rel="sudo-modal" href="/sessions/sudo_modal">
    <meta name="request-id" content="4AE0:1637D:2D37A32:4970FE8:58867E1F" data-pjax-transient>

    <meta name="msapplication-TileImage" content="/windows-tile.png">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="selected-link" value="repo_source" data-pjax-transient>

    <meta name="google-site-verification" content="KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU">
<meta name="google-site-verification" content="ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA">
    <meta name="google-analytics" content="UA-3769691-2">

<meta content="collector.githubapp.com" name="octolytics-host" /><meta content="github" name="octolytics-app-id" /><meta content="4AE0:1637D:2D37A32:4970FE8:58867E1F" name="octolytics-dimension-request_id" /><meta content="6386581" name="octolytics-actor-id" /><meta content="dojochu" name="octolytics-actor-login" /><meta content="b02e6db97cf76f7787ff972ed00bf5ba3fe243ffaa294a2c6a5c056dad8a1858" name="octolytics-actor-hash" />
<meta content="/&lt;user-name&gt;/&lt;repo-name&gt;/blob/show" data-pjax-transient="true" name="analytics-location" />



  <meta class="js-ga-set" name="dimension1" content="Logged In">



        <meta name="hostname" content="github.com">
    <meta name="user-login" content="dojochu">

        <meta name="expected-hostname" content="github.com">
      <meta name="js-proxy-site-detection-payload" content="ZjAzMDNjODRkYjRjOGQ1MTgxNjdmYmM2Mzc4ZmIxNThmMmVhNTY0MDc0Y2NiZTExZjQ0OTBkNTczNjU5ZmJmZnx7InJlbW90ZV9hZGRyZXNzIjoiMTcwLjI0OC4xNzIuMjQ1IiwicmVxdWVzdF9pZCI6IjRBRTA6MTYzN0Q6MkQzN0EzMjo0OTcwRkU4OjU4ODY3RTFGIiwidGltZXN0YW1wIjoxNDg1MjA5MTIwLCJob3N0IjoiZ2l0aHViLmNvbSJ9">


      <link rel="mask-icon" href="https://assets-cdn.github.com/pinned-octocat.svg" color="#000000">
      <link rel="icon" type="image/x-icon" href="https://assets-cdn.github.com/favicon.ico">

    <meta name="html-safe-nonce" content="25138abdfb1b1464f2d43f1325a0492b368b56d5">

    <meta http-equiv="x-pjax-version" content="7d887a4a7e9afaef47434b8286514583">
    

      
  <meta name="description" content="Contribute to DLA-Interview development by creating an account on GitHub.">
  <meta name="go-import" content="github.com/dojochu/DLA-Interview git https://github.com/dojochu/DLA-Interview.git">

  <meta content="6386581" name="octolytics-dimension-user_id" /><meta content="dojochu" name="octolytics-dimension-user_login" /><meta content="78676367" name="octolytics-dimension-repository_id" /><meta content="dojochu/DLA-Interview" name="octolytics-dimension-repository_nwo" /><meta content="true" name="octolytics-dimension-repository_public" /><meta content="false" name="octolytics-dimension-repository_is_fork" /><meta content="78676367" name="octolytics-dimension-repository_network_root_id" /><meta content="dojochu/DLA-Interview" name="octolytics-dimension-repository_network_root_nwo" />
  <link href="https://github.com/dojochu/DLA-Interview/commits/master.atom" rel="alternate" title="Recent Commits to DLA-Interview:master" type="application/atom+xml">


      <link rel="canonical" href="https://github.com/dojochu/DLA-Interview/blob/master/README.md" data-pjax-transient>
  </head>


  <body class="logged-in  env-production windows vis-public page-blob">
    <div id="js-pjax-loader-bar" class="pjax-loader-bar"><div class="progress"></div></div>
    <a href="#start-of-content" tabindex="1" class="accessibility-aid js-skip-to-content">Skip to content</a>

    
    
    



        <div class="header header-logged-in true" role="banner">
  <div class="container clearfix">

    <a class="header-logo-invertocat" href="https://github.com/" data-hotkey="g d" aria-label="Homepage" data-ga-click="Header, go to dashboard, icon:logo">
  <svg aria-hidden="true" class="octicon octicon-mark-github" height="28" version="1.1" viewBox="0 0 16 16" width="28"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>


        <div class="header-search scoped-search site-scoped-search js-site-search" role="search">
  <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/dojochu/DLA-Interview/search" class="js-site-search-form" data-scoped-search-url="/dojochu/DLA-Interview/search" data-unscoped-search-url="/search" method="get"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
    <label class="form-control header-search-wrapper js-chromeless-input-container">
      <div class="header-search-scope">This repository</div>
      <input type="text"
        class="form-control header-search-input js-site-search-focus js-site-search-field is-clearable"
        data-hotkey="s"
        name="q"
        placeholder="Search"
        aria-label="Search this repository"
        data-unscoped-placeholder="Search GitHub"
        data-scoped-placeholder="Search"
        autocapitalize="off">
    </label>
</form></div>


      <ul class="header-nav float-left" role="navigation">
        <li class="header-nav-item">
          <a href="/pulls" aria-label="Pull requests you created" class="js-selected-navigation-item header-nav-link" data-ga-click="Header, click, Nav menu - item:pulls context:user" data-hotkey="g p" data-selected-links="/pulls /pulls/assigned /pulls/mentioned /pulls">
            Pull requests
</a>        </li>
        <li class="header-nav-item">
          <a href="/issues" aria-label="Issues you created" class="js-selected-navigation-item header-nav-link" data-ga-click="Header, click, Nav menu - item:issues context:user" data-hotkey="g i" data-selected-links="/issues /issues/assigned /issues/mentioned /issues">
            Issues
</a>        </li>
          <li class="header-nav-item">
            <a class="header-nav-link" href="https://gist.github.com/" data-ga-click="Header, go to gist, text:gist">Gist</a>
          </li>
      </ul>

    
<ul class="header-nav user-nav float-right" id="user-links">
  <li class="header-nav-item">
    
    <a href="/notifications" aria-label="You have unread notifications" class="header-nav-link notification-indicator tooltipped tooltipped-s js-socket-channel js-notification-indicator" data-channel="tenant:1:notification-changed:6386581" data-ga-click="Header, go to notifications, icon:unread" data-hotkey="g n">
        <span class="mail-status unread"></span>
        <svg aria-hidden="true" class="octicon octicon-bell" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M14 12v1H0v-1l.73-.58c.77-.77.81-2.55 1.19-4.42C2.69 3.23 6 2 6 2c0-.55.45-1 1-1s1 .45 1 1c0 0 3.39 1.23 4.16 5 .38 1.88.42 3.66 1.19 4.42l.66.58H14zm-7 4c1.11 0 2-.89 2-2H5c0 1.11.89 2 2 2z"/></svg>
</a>
  </li>

  <li class="header-nav-item dropdown js-menu-container">
    <a class="header-nav-link tooltipped tooltipped-s js-menu-target" href="/new"
       aria-label="Create new…"
       data-ga-click="Header, create new, icon:add">
      <svg aria-hidden="true" class="octicon octicon-plus float-left" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M12 9H7v5H5V9H0V7h5V2h2v5h5z"/></svg>
      <span class="dropdown-caret"></span>
    </a>

    <div class="dropdown-menu-content js-menu-content">
      <ul class="dropdown-menu dropdown-menu-sw">
        
<a class="dropdown-item" href="/new" data-ga-click="Header, create new repository">
  New repository
</a>

  <a class="dropdown-item" href="/new/import" data-ga-click="Header, import a repository">
    Import repository
  </a>

<a class="dropdown-item" href="https://gist.github.com/" data-ga-click="Header, create new gist">
  New gist
</a>

  <a class="dropdown-item" href="/organizations/new" data-ga-click="Header, create new organization">
    New organization
  </a>



  <div class="dropdown-divider"></div>
  <div class="dropdown-header">
    <span title="dojochu/DLA-Interview">This repository</span>
  </div>
    <a class="dropdown-item" href="/dojochu/DLA-Interview/issues/new" data-ga-click="Header, create new issue">
      New issue
    </a>
    <a class="dropdown-item" href="/dojochu/DLA-Interview/settings/collaboration" data-ga-click="Header, create new collaborator">
      New collaborator
    </a>

      </ul>
    </div>
  </li>

  <li class="header-nav-item dropdown js-menu-container">
    <a class="header-nav-link name tooltipped tooltipped-sw js-menu-target" href="/dojochu"
       aria-label="View profile and more"
       data-ga-click="Header, show menu, icon:avatar">
      <img alt="@dojochu" class="avatar" height="20" src="https://avatars2.githubusercontent.com/u/6386581?v=3&amp;s=40" width="20" />
      <span class="dropdown-caret"></span>
    </a>

    <div class="dropdown-menu-content js-menu-content">
      <div class="dropdown-menu dropdown-menu-sw">
        <div class="dropdown-header header-nav-current-user css-truncate">
          Signed in as <strong class="css-truncate-target">dojochu</strong>
        </div>

        <div class="dropdown-divider"></div>

        <a class="dropdown-item" href="/dojochu" data-ga-click="Header, go to profile, text:your profile">
          Your profile
        </a>
        <a class="dropdown-item" href="/dojochu?tab=stars" data-ga-click="Header, go to starred repos, text:your stars">
          Your stars
        </a>
        <a class="dropdown-item" href="/explore" data-ga-click="Header, go to explore, text:explore">
          Explore
        </a>
          <a class="dropdown-item" href="/integrations" data-ga-click="Header, go to integrations, text:integrations">
            Integrations
          </a>
        <a class="dropdown-item" href="https://help.github.com" data-ga-click="Header, go to help, text:help">
          Help
        </a>

        <div class="dropdown-divider"></div>

        <a class="dropdown-item" href="/settings/profile" data-ga-click="Header, go to settings, icon:settings">
          Settings
        </a>

        <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/logout" class="logout-form" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="tKVD1FVC9/kEIFERWgNBHWLfOMZ7DTqB2imwflDOAeiqkHJZS/ZTcBOGd0377N0D8lXDn9G2HMGh0FjBTQzHlg==" /></div>
          <button type="submit" class="dropdown-item dropdown-signout" data-ga-click="Header, sign out, icon:logout">
            Sign out
          </button>
</form>      </div>
    </div>
  </li>
</ul>


    
  </div>
</div>


      


    <div id="start-of-content" class="accessibility-aid"></div>

      <div id="js-flash-container">
</div>


    <div role="main">
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode">
    <div id="js-repo-pjax-container" data-pjax-container>
      
<div class="pagehead repohead instapaper_ignore readability-menu experiment-repo-nav">
  <div class="container repohead-details-container">

    

<ul class="pagehead-actions">

  <li>
        <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/notifications/subscribe" class="js-social-container" data-autosubmit="true" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="5qIv07OlFOh4oxQC8l5C0UUtdOVsbn5x6527Wc7yRjKdGw8ES7w4bDj5i0hMfc8EWAgQn5NgMhWrFfo9u/exVw==" /></div>      <input class="form-control" id="repository_id" name="repository_id" type="hidden" value="78676367" />

        <div class="select-menu js-menu-container js-select-menu">
          <a href="/dojochu/DLA-Interview/subscription"
            class="btn btn-sm btn-with-count select-menu-button js-menu-target" role="button" tabindex="0" aria-haspopup="true"
            data-ga-click="Repository, click Watch settings, action:blob#show">
            <span class="js-select-button">
              <svg aria-hidden="true" class="octicon octicon-eye" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
              Unwatch
            </span>
          </a>
          <a class="social-count js-social-count"
            href="/dojochu/DLA-Interview/watchers"
            aria-label="1 user is watching this repository">
            1
          </a>

        <div class="select-menu-modal-holder">
          <div class="select-menu-modal subscription-menu-modal js-menu-content" aria-hidden="true">
            <div class="select-menu-header js-navigation-enable" tabindex="-1">
              <svg aria-label="Close" class="octicon octicon-x js-menu-close" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
              <span class="select-menu-title">Notifications</span>
            </div>

              <div class="select-menu-list js-navigation-container" role="menu">

                <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
                  <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5z"/></svg>
                  <div class="select-menu-item-text">
                    <input id="do_included" name="do" type="radio" value="included" />
                    <span class="select-menu-item-heading">Not watching</span>
                    <span class="description">Be notified when participating or @mentioned.</span>
                    <span class="js-select-button-text hidden-select-button-text">
                      <svg aria-hidden="true" class="octicon octicon-eye" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                      Watch
                    </span>
                  </div>
                </div>

                <div class="select-menu-item js-navigation-item selected" role="menuitem" tabindex="0">
                  <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5z"/></svg>
                  <div class="select-menu-item-text">
                    <input checked="checked" id="do_subscribed" name="do" type="radio" value="subscribed" />
                    <span class="select-menu-item-heading">Watching</span>
                    <span class="description">Be notified of all conversations.</span>
                    <span class="js-select-button-text hidden-select-button-text">
                      <svg aria-hidden="true" class="octicon octicon-eye" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                      Unwatch
                    </span>
                  </div>
                </div>

                <div class="select-menu-item js-navigation-item " role="menuitem" tabindex="0">
                  <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5z"/></svg>
                  <div class="select-menu-item-text">
                    <input id="do_ignore" name="do" type="radio" value="ignore" />
                    <span class="select-menu-item-heading">Ignoring</span>
                    <span class="description">Never be notified.</span>
                    <span class="js-select-button-text hidden-select-button-text">
                      <svg aria-hidden="true" class="octicon octicon-mute" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M8 2.81v10.38c0 .67-.81 1-1.28.53L3 10H1c-.55 0-1-.45-1-1V7c0-.55.45-1 1-1h2l3.72-3.72C7.19 1.81 8 2.14 8 2.81zm7.53 3.22l-1.06-1.06-1.97 1.97-1.97-1.97-1.06 1.06L11.44 8 9.47 9.97l1.06 1.06 1.97-1.97 1.97 1.97 1.06-1.06L13.56 8l1.97-1.97z"/></svg>
                      Stop ignoring
                    </span>
                  </div>
                </div>

              </div>

            </div>
          </div>
        </div>
</form>
  </li>

  <li>
      <div class="js-toggler-container js-social-container starring-container ">
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/dojochu/DLA-Interview/unstar" class="starred" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="npZIjb7TYV0/o1eijtMwfdZcgTaXM3E97RjsvBMtY1BoMfCLEV9Xc9lfgFyzATK85nQ0YHicNWivjPBJB6WL7g==" /></div>
      <button
        type="submit"
        class="btn btn-sm btn-with-count js-toggler-target"
        aria-label="Unstar this repository" title="Unstar dojochu/DLA-Interview"
        data-ga-click="Repository, click unstar button, action:blob#show; text:Unstar">
        <svg aria-hidden="true" class="octicon octicon-star" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74z"/></svg>
        Unstar
      </button>
        <a class="social-count js-social-count" href="/dojochu/DLA-Interview/stargazers"
           aria-label="0 users starred this repository">
          0
        </a>
</form>
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/dojochu/DLA-Interview/star" class="unstarred" data-remote="true" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="FiDjU4Kx3sNwc+RLtMN1dVefGA9H8H79WS/FMfOCDEIcX0K3TjKGxVYxaupLqgnQ1rON87AwCBgGFS6tya4bFQ==" /></div>
      <button
        type="submit"
        class="btn btn-sm btn-with-count js-toggler-target"
        aria-label="Star this repository" title="Star dojochu/DLA-Interview"
        data-ga-click="Repository, click star button, action:blob#show; text:Star">
        <svg aria-hidden="true" class="octicon octicon-star" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74z"/></svg>
        Star
      </button>
        <a class="social-count js-social-count" href="/dojochu/DLA-Interview/stargazers"
           aria-label="0 users starred this repository">
          0
        </a>
</form>  </div>

  </li>

  <li>
          <a href="#fork-destination-box" class="btn btn-sm btn-with-count"
              title="Fork your own copy of dojochu/DLA-Interview to your account"
              aria-label="Fork your own copy of dojochu/DLA-Interview to your account"
              rel="facebox"
              data-ga-click="Repository, show fork modal, action:blob#show; text:Fork">
              <svg aria-hidden="true" class="octicon octicon-repo-forked" height="16" version="1.1" viewBox="0 0 10 16" width="10"><path fill-rule="evenodd" d="M8 1a1.993 1.993 0 0 0-1 3.72V6L5 8 3 6V4.72A1.993 1.993 0 0 0 2 1a1.993 1.993 0 0 0-1 3.72V6.5l3 3v1.78A1.993 1.993 0 0 0 5 15a1.993 1.993 0 0 0 1-3.72V9.5l3-3V4.72A1.993 1.993 0 0 0 8 1zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3 10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3-10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
            Fork
          </a>

          <div id="fork-destination-box" style="display: none;">
            <h2 class="facebox-header" data-facebox-id="facebox-header">Where should we fork this repository?</h2>
            <include-fragment src=""
                class="js-fork-select-fragment fork-select-fragment"
                data-url="/dojochu/DLA-Interview/fork?fragment=1">
              <img alt="Loading" height="64" src="https://assets-cdn.github.com/images/spinners/octocat-spinner-128.gif" width="64" />
            </include-fragment>
          </div>

    <a href="/dojochu/DLA-Interview/network" class="social-count"
       aria-label="0 users forked this repository">
      0
    </a>
  </li>
</ul>

    <h1 class="public ">
  <svg aria-hidden="true" class="octicon octicon-repo" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z"/></svg>
  <span class="author" itemprop="author"><a href="/dojochu" class="url fn" rel="author">dojochu</a></span><!--
--><span class="path-divider">/</span><!--
--><strong itemprop="name"><a href="/dojochu/DLA-Interview" data-pjax="#js-repo-pjax-container">DLA-Interview</a></strong>

</h1>

  </div>
  <div class="container">
    
<nav class="reponav js-repo-nav js-sidenav-container-pjax"
     itemscope
     itemtype="http://schema.org/BreadcrumbList"
     role="navigation"
     data-pjax="#js-repo-pjax-container">

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a href="/dojochu/DLA-Interview" class="js-selected-navigation-item selected reponav-item" data-hotkey="g c" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches /dojochu/DLA-Interview" itemprop="url">
      <svg aria-hidden="true" class="octicon octicon-code" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M9.5 3L8 4.5 11.5 8 8 11.5 9.5 13 14 8 9.5 3zm-5 0L0 8l4.5 5L6 11.5 2.5 8 6 4.5 4.5 3z"/></svg>
      <span itemprop="name">Code</span>
      <meta itemprop="position" content="1">
</a>  </span>

    <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
      <a href="/dojochu/DLA-Interview/issues" class="js-selected-navigation-item reponav-item" data-hotkey="g i" data-selected-links="repo_issues repo_labels repo_milestones /dojochu/DLA-Interview/issues" itemprop="url">
        <svg aria-hidden="true" class="octicon octicon-issue-opened" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg>
        <span itemprop="name">Issues</span>
        <span class="counter">0</span>
        <meta itemprop="position" content="2">
</a>    </span>

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a href="/dojochu/DLA-Interview/pulls" class="js-selected-navigation-item reponav-item" data-hotkey="g p" data-selected-links="repo_pulls /dojochu/DLA-Interview/pulls" itemprop="url">
      <svg aria-hidden="true" class="octicon octicon-git-pull-request" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
      <span itemprop="name">Pull requests</span>
      <span class="counter">0</span>
      <meta itemprop="position" content="3">
</a>  </span>

  <a href="/dojochu/DLA-Interview/projects" class="js-selected-navigation-item reponav-item" data-selected-links="repo_projects new_repo_project repo_project /dojochu/DLA-Interview/projects">
    <svg aria-hidden="true" class="octicon octicon-project" height="16" version="1.1" viewBox="0 0 15 16" width="15"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
    Projects
    <span class="counter">0</span>
</a>
    <a href="/dojochu/DLA-Interview/wiki" class="js-selected-navigation-item reponav-item" data-hotkey="g w" data-selected-links="repo_wiki /dojochu/DLA-Interview/wiki">
      <svg aria-hidden="true" class="octicon octicon-book" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z"/></svg>
      Wiki
</a>

  <a href="/dojochu/DLA-Interview/pulse" class="js-selected-navigation-item reponav-item" data-selected-links="pulse /dojochu/DLA-Interview/pulse">
    <svg aria-hidden="true" class="octicon octicon-pulse" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M11.5 8L8.8 5.4 6.6 8.5 5.5 1.6 2.38 8H0v2h3.6l.9-1.8.9 5.4L9 8.5l1.6 1.5H14V8z"/></svg>
    Pulse
</a>
  <a href="/dojochu/DLA-Interview/graphs" class="js-selected-navigation-item reponav-item" data-selected-links="repo_graphs repo_contributors /dojochu/DLA-Interview/graphs">
    <svg aria-hidden="true" class="octicon octicon-graph" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M16 14v1H0V0h1v14h15zM5 13H3V8h2v5zm4 0H7V3h2v10zm4 0h-2V6h2v7z"/></svg>
    Graphs
</a>
    <a href="/dojochu/DLA-Interview/settings" class="js-selected-navigation-item reponav-item" data-selected-links="repo_settings repo_branch_settings hooks integration_installations /dojochu/DLA-Interview/settings">
      <svg aria-hidden="true" class="octicon octicon-gear" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M14 8.77v-1.6l-1.94-.64-.45-1.09.88-1.84-1.13-1.13-1.81.91-1.09-.45-.69-1.92h-1.6l-.63 1.94-1.11.45-1.84-.88-1.13 1.13.91 1.81-.45 1.09L0 7.23v1.59l1.94.64.45 1.09-.88 1.84 1.13 1.13 1.81-.91 1.09.45.69 1.92h1.59l.63-1.94 1.11-.45 1.84.88 1.13-1.13-.92-1.81.47-1.09L14 8.75v.02zM7 11c-1.66 0-3-1.34-3-3s1.34-3 3-3 3 1.34 3 3-1.34 3-3 3z"/></svg>
      Settings
</a>
</nav>

  </div>
</div>

<div class="container new-discussion-timeline experiment-repo-nav">
  <div class="repository-content">

    

<a href="/dojochu/DLA-Interview/blob/a472d7ca1509961aa2f9de22810fb49739907bc7/README.md" class="d-none js-permalink-shortcut" data-hotkey="y">Permalink</a>

<!-- blob contrib key: blob_contributors:v21:f8eb59d543b13df1a4505d873a9f04ee -->

<div class="file-navigation js-zeroclipboard-container">
  
<div class="select-menu branch-select-menu js-menu-container js-select-menu float-left">
  <button class="btn btn-sm select-menu-button js-menu-target css-truncate" data-hotkey="w"
    
    type="button" aria-label="Switch branches or tags" tabindex="0" aria-haspopup="true">
    <i>Branch:</i>
    <span class="js-select-button css-truncate-target">master</span>
  </button>

  <div class="select-menu-modal-holder js-menu-content js-navigation-container" data-pjax aria-hidden="true">

    <div class="select-menu-modal">
      <div class="select-menu-header">
        <svg aria-label="Close" class="octicon octicon-x js-menu-close" height="16" role="img" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
        <span class="select-menu-title">Switch branches/tags</span>
      </div>

      <div class="select-menu-filters">
        <div class="select-menu-text-filter">
          <input type="text" aria-label="Find or create a branch…" id="context-commitish-filter-field" class="form-control js-filterable-field js-navigation-enable" placeholder="Find or create a branch…">
        </div>
        <div class="select-menu-tabs">
          <ul>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="branches" data-filter-placeholder="Find or create a branch…" class="js-select-menu-tab" role="tab">Branches</a>
            </li>
            <li class="select-menu-tab">
              <a href="#" data-tab-filter="tags" data-filter-placeholder="Find a tag…" class="js-select-menu-tab" role="tab">Tags</a>
            </li>
          </ul>
        </div>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="branches" role="menu">

        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


            <a class="select-menu-item js-navigation-item js-navigation-open selected"
               href="/dojochu/DLA-Interview/blob/master/README.md"
               data-name="master"
               data-skip-pjax="true"
               rel="nofollow">
              <svg aria-hidden="true" class="octicon octicon-check select-menu-item-icon" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5z"/></svg>
              <span class="select-menu-item-text css-truncate-target js-select-menu-filter-text">
                master
              </span>
            </a>
        </div>

          <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/dojochu/DLA-Interview/branches" class="js-create-branch select-menu-item select-menu-new-item-form js-navigation-item js-new-item-form" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="FnBUvDMZGze92D4tCqnb1fv0NIRL1Kcw2cdrbCVNXGD5yyL/iw3FI4rjgUYBNzoYiNb0kJM0sqRTDByOjAgMDw==" /></div>
          <svg aria-hidden="true" class="octicon octicon-git-branch select-menu-item-icon" height="16" version="1.1" viewBox="0 0 10 16" width="10"><path fill-rule="evenodd" d="M10 5c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v.3c-.02.52-.23.98-.63 1.38-.4.4-.86.61-1.38.63-.83.02-1.48.16-2 .45V4.72a1.993 1.993 0 0 0-1-3.72C.88 1 0 1.89 0 3a2 2 0 0 0 1 1.72v6.56c-.59.35-1 .99-1 1.72 0 1.11.89 2 2 2 1.11 0 2-.89 2-2 0-.53-.2-1-.53-1.36.09-.06.48-.41.59-.47.25-.11.56-.17.94-.17 1.05-.05 1.95-.45 2.75-1.25S8.95 7.77 9 6.73h-.02C9.59 6.37 10 5.73 10 5zM2 1.8c.66 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2C1.35 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2zm0 12.41c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm6-8c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
            <div class="select-menu-item-text">
              <span class="select-menu-item-heading">Create branch: <span class="js-new-item-name"></span></span>
              <span class="description">from ‘master’</span>
            </div>
            <input type="hidden" name="name" id="name" class="js-new-item-value">
            <input type="hidden" name="branch" id="branch" value="master">
            <input type="hidden" name="path" id="path" value="README.md">
</form>
      </div>

      <div class="select-menu-list select-menu-tab-bucket js-select-menu-tab-bucket" data-tab-filter="tags">
        <div data-filterable-for="context-commitish-filter-field" data-filterable-type="substring">


        </div>

        <div class="select-menu-no-results">Nothing to show</div>
      </div>

    </div>
  </div>
</div>

  <div class="BtnGroup float-right">
    <a href="/dojochu/DLA-Interview/find/master"
          class="js-pjax-capture-input btn btn-sm BtnGroup-item"
          data-pjax
          data-hotkey="t">
      Find file
    </a>
    <button aria-label="Copy file path to clipboard" class="js-zeroclipboard btn btn-sm BtnGroup-item tooltipped tooltipped-s" data-copied-hint="Copied!" type="button">Copy path</button>
  </div>
  <div class="breadcrumb js-zeroclipboard-target">
    <span class="repo-root js-repo-root"><span class="js-path-segment"><a href="/dojochu/DLA-Interview"><span>DLA-Interview</span></a></span></span><span class="separator">/</span><strong class="final-path">README.md</strong>
  </div>
</div>


  <div class="commit-tease">
      <span class="float-right">
        <a class="commit-tease-sha" href="/dojochu/DLA-Interview/commit/a472d7ca1509961aa2f9de22810fb49739907bc7" data-pjax>
          a472d7c
        </a>
        <relative-time datetime="2017-01-22T19:28:09Z">Jan 22, 2017</relative-time>
      </span>
      <div>
        <img alt="" class="avatar" data-canonical-src="https://0.gravatar.com/avatar/b89c8828c7593a12072cc7e94b6a6720?d=https%3A%2F%2Fassets-cdn.github.com%2Fimages%2Fgravatars%2Fgravatar-user-420.png&amp;r=x&amp;s=140" height="20" src="https://camo.githubusercontent.com/6437d260cf0f4ce5d84d616cbf1fa9c0900c4808/68747470733a2f2f302e67726176617461722e636f6d2f6176617461722f62383963383832386337353933613132303732636337653934623661363732303f643d68747470732533412532462532466173736574732d63646e2e6769746875622e636f6d253246696d6167657325324667726176617461727325324667726176617461722d757365722d3432302e706e6726723d7826733d313430" width="20" />
        <span class="user-mention">Stephanie Kao</span>
          <a href="/dojochu/DLA-Interview/commit/a472d7ca1509961aa2f9de22810fb49739907bc7" class="message" data-pjax="true" title="DLA Submission">DLA Submission</a>
      </div>

    <div class="commit-tease-contributors">
      <button type="button" class="btn-link muted-link contributors-toggle" data-facebox="#blob_contributors_box">
        <strong>0</strong>
         contributors
      </button>
      
    </div>

    <div id="blob_contributors_box" style="display:none">
      <h2 class="facebox-header" data-facebox-id="facebox-header">Users who have contributed to this file</h2>
      <ul class="facebox-user-list" data-facebox-id="facebox-description">
      </ul>
    </div>
  </div>


<div class="file">
  <div class="file-header">
  <div class="file-actions">

    <div class="BtnGroup">
      <a href="/dojochu/DLA-Interview/raw/master/README.md" class="btn btn-sm BtnGroup-item" id="raw-url">Raw</a>
        <a href="/dojochu/DLA-Interview/blame/master/README.md" class="btn btn-sm js-update-url-with-hash BtnGroup-item" data-hotkey="b">Blame</a>
      <a href="/dojochu/DLA-Interview/commits/master/README.md" class="btn btn-sm BtnGroup-item" rel="nofollow">History</a>
    </div>

        <a class="btn-octicon tooltipped tooltipped-nw"
           href="github-windows://openRepo/https://github.com/dojochu/DLA-Interview?branch=master&amp;filepath=README.md"
           aria-label="Open this file in GitHub Desktop"
           data-ga-click="Repository, open with desktop, type:windows">
            <svg aria-hidden="true" class="octicon octicon-device-desktop" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M15 2H1c-.55 0-1 .45-1 1v9c0 .55.45 1 1 1h5.34c-.25.61-.86 1.39-2.34 2h8c-1.48-.61-2.09-1.39-2.34-2H15c.55 0 1-.45 1-1V3c0-.55-.45-1-1-1zm0 9H1V3h14v8z"/></svg>
        </a>

        <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/dojochu/DLA-Interview/edit/master/README.md" class="inline-form js-update-url-with-hash" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="phHf1qwn/0PjGEftgUB2yctjm1ZeULUcSRddP/2G5G9m1HUmIsh7dHMXrAguZnZZbW5gemw4fi+gvbyJubPSUA==" /></div>
          <button class="btn-octicon tooltipped tooltipped-nw" type="submit"
            aria-label="Edit this file" data-hotkey="e" data-disable-with>
            <svg aria-hidden="true" class="octicon octicon-pencil" height="16" version="1.1" viewBox="0 0 14 16" width="14"><path fill-rule="evenodd" d="M0 12v3h3l8-8-3-3-8 8zm3 2H1v-2h1v1h1v1zm10.3-9.3L12 6 9 3l1.3-1.3a.996.996 0 0 1 1.41 0l1.59 1.59c.39.39.39 1.02 0 1.41z"/></svg>
          </button>
</form>        <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="/dojochu/DLA-Interview/delete/master/README.md" class="inline-form" method="post"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /><input name="authenticity_token" type="hidden" value="28fEDeYVFQRSOmtKIyNrUQQ0lA6mNq048in6N1jw1xfEmfzKqIYjdbUVZxCwZE+Pk4Ao7pe59iX6MaM1mG2KMA==" /></div>
          <button class="btn-octicon btn-octicon-danger tooltipped tooltipped-nw" type="submit"
            aria-label="Delete this file" data-disable-with>
            <svg aria-hidden="true" class="octicon octicon-trashcan" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M11 2H9c0-.55-.45-1-1-1H5c-.55 0-1 .45-1 1H2c-.55 0-1 .45-1 1v1c0 .55.45 1 1 1v9c0 .55.45 1 1 1h7c.55 0 1-.45 1-1V5c.55 0 1-.45 1-1V3c0-.55-.45-1-1-1zm-1 12H3V5h1v8h1V5h1v8h1V5h1v8h1V5h1v9zm1-10H2V3h9v1z"/></svg>
          </button>
</form>  </div>

  <div class="file-info">
      298 lines (192 sloc)
      <span class="file-info-divider"></span>
    24.6 KB
  </div>
</div>

  
  <div id="readme" class="readme blob instapaper_body">
    <article class="markdown-body entry-content" itemprop="text"><h1><a id="user-content-dla-interview-project" class="anchor" href="#dla-interview-project" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>DLA Interview Project</h1>

<h2><a id="user-content-author" class="anchor" href="#author" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Author</h2>

<ul>
<li>Name: Stephanie Kao</li>
<li>Email: <a href="mailto:stephanie.kao5@gmail.com">stephanie.kao5@gmail.com</a></li>
<li>Phone: 775-544-9655</li>
</ul>

<p>This README describes the development of an automated music genre tagger - a machine learning model that uses deep neural networks to categorize audio signals from a music file into one or more musical genre. This project focuses on deep learning architectures and analyzing/visualizing the results for improvements. The hope is to provide insight into the data patterns of audio signals and its association with genre. To access this README in more readable form, type the following in the terminal:</p>

<pre><code>grip -b ~/dla/DLA/README.md 8080
</code></pre>

<h2><a id="user-content-problem-scope" class="anchor" href="#problem-scope" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Problem Scope</h2>

<p>Many music applications and recommendation engines rely upon tags/annotations to identify music files. Musical genre (rock, pop, hip-hop, gospel, etc) is an important tag to help categorize music and define musical taste. There is an interest to understand patterns in audio signals and whether they emulate a particular kind of musical genre. <strong>The goal is to take a snippet audio signal from a song file and predict its musical genre (sans any other knowledge of the song such artist, song name, lyrics)</strong>. Further applications of this problem include identifying new genres or groupings of audio signals, censoring/filtering/tagging incoming audio such as live TV censorship, and exploring signal patterns that are appeasing to the listener. What sound patterns do hardcore rock listeners enjoy as opposed to classical music listeners? Can this improve music recommendation?</p>

<p>The ground truth dataset is complicated and ambiguous for a couple reasons. (1) A song can fall into multiple genres (2) People classify songs differently and subjectively and so there is no "standard" classification dictionary. Certainly, the set of genres to use in classification is important. How do we define the set of genres? </p>

<p>One way to approach this problem is to establish a diverse set of characterizations for music. These characterizations must be as comprehensive and generalized as possible. This way, an external party using the characterizations have the flexibility to define their own genre mapping. A song that is characterized by 'eerie', 'chanting', and 'dark' may be mapped to cult music by one opinion or mapped to haunting music by another. The model's purpose is to predict the characterizations and not be concerned with genre. The model should be able to predict several characterizations for the song in question. <strong>Although this approach complicates the machine learning problem, it allows music to be a blend of several categories (which it should) and it asserts an objective characterization of music rather than a subjective labeling of genres.</strong> For instance, it is a fact that a song contains bongos but it is a matter of opinion whether it's NY street music or tribal music. Lastly, this approach will broaden our ability to dissect the complexity of audio signals and identify how our feature maps can represent different blends.</p>

<p>This project will utilize the following annotation tags from <a href="http://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset">MagnaTagATune DataSet</a> for the model's characterization set:</p>

<pre><code>['no voice', 'singer', 'duet', 'plucking', 'hard rock', 'world', 'bongos', 'harpsichord', 'female singing', 'clasical', 'sitar', 'chorus', 'female opera', 'male vocal', 'vocals', 'clarinet', 'heavy', 'silence', 'beats', 'men', 'woodwind', 'funky', 'no strings', 'chimes', 'foreign', 'no piano', 'horns', 'classical', 'female', 'no voices', 'soft rock', 'eerie', 'spacey', 'jazz', 'guitar', 'quiet', 'no beat', 'banjo', 'electric', 'solo', 'violins', 'folk', 'female voice', 'wind', 'happy', 'ambient', 'new age', 'synth', 'funk', 'no singing', 'middle eastern', 'trumpet', 'percussion', 'drum', 'airy', 'voice', 'repetitive', 'birds', 'space', 'strings', 'bass', 'harpsicord', 'medieval', 'male voice', 'girl', 'keyboard', 'acoustic', 'loud', 'classic', 'string', 'drums', 'electronic', 'not classical', 'chanting', 'no violin', 'not rock', 'no guitar', 'organ', 'no vocal', 'talking', 'choral', 'weird', 'opera', 'soprano', 'fast', 'acoustic guitar', 'electric guitar', 'male singer', 'man singing', 'classical guitar', 'country', 'violin', 'electro', 'reggae', 'tribal', 'dark', 'male opera', 'no vocals', 'irish', 'electronica', 'horn', 'operatic', 'arabic', 'lol', 'low', 'instrumental', 'trance', 'chant', 'strange', 'drone', 'synthesizer', 'heavy metal', 'modern', 'disco', 'bells', 'man', 'deep', 'fast beat', 'industrial', 'hard', 'harp', 'no flute', 'jungle', 'pop', 'lute', 'female vocal', 'oboe', 'mellow', 'orchestral', 'viola', 'light', 'echo', 'piano', 'celtic', 'male vocals', 'orchestra', 'eastern', 'old', 'flutes', 'punk', 'spanish', 'sad', 'sax', 'slow', 'male', 'blues', 'vocal', 'indian', 'no singer', 'scary', 'india', 'woman', 'woman singing', 'rock', 'dance', 'piano solo', 'guitars', 'no drums', 'jazzy', 'singing', 'cello', 'calm', 'female vocals', 'voices', 'different', 'techno', 'clapping', 'house', 'monks', 'flute', 'not opera', 'not english', 'oriental', 'beat', 'upbeat', 'soft', 'noise', 'choir', 'female singer', 'rap', 'metal', 'hip hop', 'quick', 'water', 'baroque', 'women', 'fiddle', 'english']

</code></pre>

<p><em>188 Music Characterizations</em></p>

<h2><a id="user-content-getting-started" class="anchor" href="#getting-started" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Getting Started</h2>

<p>These instructions will get the project up and running on this machine. </p>

<p>The model was built in a python virtual environment using virutalenv. Activate the environment typing the following command in the terminal:</p>

<pre><code>source ~/dla/bin/activate
</code></pre>

<p>All the necessary python packages required to run the model should be available in this environment. Type 'deactivate' to close the environment.</p>

<p>To tag a music file on a default audiofile Sparks.mp3, run the <code>music_tagger.py</code> as follows:</p>

<pre><code>python music_tagger.py -m CNN3
</code></pre>

<p>You may choose from models CNN, CNN2, CNN3. The third model is recommended. There are music files in the <code>music_samples</code> folder that you may use or you can provide your own music file.</p>

<pre><code>python music_tagger.py -m CNN3 -a '/home/ubuntu/dla/DLA/music_samples/MagnaSample/Sparks.mp3'
</code></pre>

<p>You can run the model one of the batch mp3 datasets (f,e,d,c,0,1,2,3,4,5,6,7,8,9) (NOTE: the RAM may not be able to fit the entire batch. Try the 'f' batch):</p>

<pre><code>python music_tagger.py -m CNN3 -d f
python music_tagger.py -m CNN3 -d 0
</code></pre>

<p>You can reproduce spectrogram plots using functions in <code>testing.py</code> and <code>music_analysis.py</code>. There are comments and documentation in the code.</p>

<pre><code>import music_analysis as ma
import testing

#Run analysis on test data
results = testing.testOnBatch('CNN3', ['f'])
testing.plotResults(results, 0, 10)
topKMet, tableRate = testing.topKMetric(results, 10, 0.80)
testing.plotTopKROC(results, 5, 0.1)

#Run 4 sample spectrograms on violin music
ma.sample('violin', 4)

</code></pre>

<h2><a id="user-content-files" class="anchor" href="#files" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Files</h2>

<ul>
<li>music_tagger.py - main program file</li>
<li>music_analysis.py - For viewing spectrograms</li>
<li>audio_processor.py - Tools for reading audio music files and converts audio files to .wav if necessary. Also, reads the music files in batches for training and testing</li>
<li>training.py files - You can skim the architecture of the various deep learning models</li>
<li>testing.py - Use to test for model selection and validate final model. Also provides tools for evaluating the model's performance.</li>
</ul>

<h2><a id="user-content-software" class="anchor" href="#software" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Software</h2>

<p>The music tagger model was trained and developed in Python using the Keras Deep Learning library with a Theano backend. Keras was chosen over other Deep Learning tools, because it is a high-level Python library that allows for fast experimentation. The library easily integrates with other data manipulation tools like NumPy and a rich set of audio processing tools like Librosa. Since the CUDA 8.0 toolkit and cuDNNv5 were already installed on the Jetson TX1, Theano and Tensorflow were natural choices for taking advantage of the GPU backend. Theano was ultimately chosen over Tensorflow for the interest of time. Tensorflow requires an elaborate build on the 64ARM processor whereas Theano was fairly easy to install. With more time, the Tensorflow library might be considered for its visualization tools (TensorBoard) to aid result analysis.</p>

<h2><a id="user-content-dataset" class="anchor" href="#dataset" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Dataset</h2>

<p>Audio files from various genres of music is the primary dataset required for this problem. The ability to obtain open-source audio data is often difficult due to copyright laws and restrictions. The <a href="http://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset">MagnaTagATune DataSet</a> is an audio dataset with ~18,000 music files (about 3GB) and was chosen for this project not only because it has ready-to-download mp3 snippets, but it also provides annotation tags (labels!) to use for training. The MTAT dataset represents a wide variety of different musical genres which will allow the model to generalize well.</p>

<p>If you are familiar with audio analysis, you can skim the background and feature engineering sections or skip to the modeling portion of this README. </p>

<h3><a id="user-content-background" class="anchor" href="#background" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Background</h3>

<p>Audio data is typically represented by signals, more specifically, sinusoidal waves that resonate up and down over time. The number of times a wave reaches a peak or a trough in some defined period of time (usually per second) is its frequency while the magnitude of these peaks/troughs is its amplitude. Sounds will change with variations in frequency and amplitude. For instance, sound pitch is affected by the frequency of the waves while volume or loudness is dependent on the amplitude of the waves. The image below is an example of an audio signal for a musical snippet by Bach. In order to keep the data within a manageable size, the amplitude of the audio signal is sampled a number of instances over some duration of time. This is called the sample rate. Just like how more data can be generated for images by cropping, rotating, tinting, and apply other filters on them, we can create more data for the audio signals by sampling different snippets of the audio file.</p>

<p><a href="/dojochu/DLA-Interview/blob/master/images/figure_2.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/figure_2.png" alt="Sample Audio Signal" title="Sampled Audio Signal" style="max-width:100%;"></a>
<em>Audio signal data from 1/4 second of a song by Bach with sample rate 6000</em></p>

<h3><a id="user-content-data-analysis--feature-engineering" class="anchor" href="#data-analysis--feature-engineering" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Analysis &amp; Feature Engineering</h3>

<p>There are a few data pre-processing steps required prior to the modeling step:</p>

<ol>
<li>Create a data vector by sampling the audio file at a sample rate (SR=12000) for a duration in seconds (DURA=29.12 seconds). Our data vector has length SR*DURA.</li>
<li>If necessary, convert audio files to .wav (e.g. if they are mp3)</li>
<li>Apply Mel-Spectrogram transformation on the data vector (i.e. compute the spectrogram of the data vector and use the mel-space filter)</li>
</ol>

<p>The resulting feature matrix after Step 3 is the initial input into the deep learning model. There is a good reason to use the Mel-Spectrogram transformation on the sampled audio data prior to model training/testing that will become clear after understanding the mechanics of the spectrogram. The spectrogram technique utilizes a Short-Time Fourier Transform (STFT) on the audio signals. The STFT takes overlapping segments of the audio data and converts them from signal wave space to frequency space using a Fourier transform. The converted segments are then plotted side-by-side to unveil the discrete Fourier spectrum over time. The Fourier spectrum will appear continuous as the segments overlap more. The segments are defined by a window size of length N_FFT and created by sliding the window over a length HOP_LEN to establish the next segment. The Fourier transform is then applied to each segment. Lastly, the Mel-space filter is used to rescale the frequency measurements. This filter is meant to map the data to a frequency space that it is closer to a human listener's perception of pitch. </p>

<p>You can see examples of the Mel-Spectrogram outputs below and compare patterns across various genres of music. </p>

<ul>
<li>Song #1: None</li>
<li>Song #2: Classical, Violin <g-emoji alias="violin" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f3bb.png" ios-version="6.0">🎻</g-emoji></li>
<li>Song #3: Rock</li>
<li>Song #4: Guitar, Fast, Electric Guitar, Rock <g-emoji alias="guitar" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f3b8.png" ios-version="6.0">🎸</g-emoji></li>
<li>Song #5: None</li>
<li>Song #6: New Age</li>
</ul>

<p><em>Mel-Spectrogram plots for 6 different songs. Note: Brighter colors indicate high amplitude.</em>
<a href="/dojochu/DLA-Interview/blob/master/images/figure_1.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/figure_1.png" alt="Mel-Spectrogram" title="Mel-Spectrogram" style="max-width:100%;"></a></p>

<p>Each vertical line in the spectrogram represents the Fourier transform of a segment with the colors representing amplitude. The x-axis corresponds to time; the y-axis corresponds to frequency; the color corresponds to amplitude. Patterns in the Mel-Spectrogram can reveal and distinguish different voices/instruments of music. For instance, music with a male voice typically have bright colors in the lower area of the spectrogram. This is because the low pitch of male voices emit lower frequencies and so you will often see high amplitude of waves at a lower frequency. On the other hand, female voices often sing higher pitches and will emit high frequencies at a high amplitude. Songs with female voices will have bright colors in the upper area of the spectrogram. <strong>The advantage of the Mel-Spectrogram is creating a feature space similiar to images. Specifically, the data is represented as a 2-dimensional matrix of pixels. With this setup, similiar techniques from deep learning in image recognition can be reused to build the music tagger deep learning model.</strong></p>

<h2><a id="user-content-modeling" class="anchor" href="#modeling" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Modeling</h2>

<h3><a id="user-content-mel-spectrogram-parameters" class="anchor" href="#mel-spectrogram-parameters" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Mel-Spectrogram parameters</h3>

<p>The parameters chosen for the input data were based on research done by <a href="https://arxiv.org/pdf/1606.00298v1.pdf">Keunwoo Choi</a>.  He has made his CNN and RNN music tagger open source and provides helpful guidance in how to train a music tagger using deep neural network methodologies. The model trained for this project will use his research heavily but sets up the problem scope differently and includes additional work on analyzing the results which isn't discussed in Keunwoo's work. Keunwoo attempts to predict musical genre directly whereas this project only attempts to predict music characterizations.  The Mel-Spectrogram data was cached on a hard drive in order to apply the feature transformation once and not on every read.</p>

<ul>
<li>Sample Rate = 12000</li>
<li>Window Size = 1024</li>
<li>Hop Length = 512</li>
<li>Mel Bins = 48</li>
<li>Duration = 29.12</li>
</ul>

<h3><a id="user-content-machine-learning-model" class="anchor" href="#machine-learning-model" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning Model</h3>

<p>The machine learning model is a 6-layer Convolutional Deep Neural Network (CNN) with a fully connected layer in the final output. The 2D-convolutional layers are subsampled with Max Pooling to reduce the number of parameters and extract higher-level features. Model training took place on ~13,000 mp3 snippets provided by the MTAT dataset using batches of size 5. The batches were small because the large number of parameters in the CNN and feature inputs (1x96x1966 dimensional matrices) barely fit into 4GB of RAM. Small batch sizes can cause volatile computations in the gradient at each learning step and possibly slow down or worsen training. However, training on a large dataset allows the deep learning model to compensate for poor gradient calculations and help move the optimizer toward a minimal cost function. Increasing the RAM to accommodate larger batch sizes would be ideal but is not an option at the moment. The Mel-Spectrogram parameters can also be altered to produce a more compressed input vector with some concern for loss of important information. The batch of size 5 was the compromise. Also due to RAM limitations, training any CNN deeper than the one shown below is difficult. It takes just over 2 hours to train the model.</p>

<p><em>6-Layer Convolutional Neural Network Architecture for Music Tagging</em></p>

<p><a href="/dojochu/DLA-Interview/blob/master/images/CNN3.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/CNN3.png" alt="CNN model" style="max-width:100%;"></a></p>

<h3><a id="user-content-cnn-architecture" class="anchor" href="#cnn-architecture" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>CNN Architecture</h3>

<p>The computational challenge in this architecture was training a CNN model that could be held in RAM throughout the training process. The large output vector (size N = 188) caused issues towards the end of the CNN model. Since the last layer is a fully connected dense layer, the number of parameters required to compute the final layer could be enormous (188*?). The last max pooling layer is flattened which further exacerbated the issue. The thought process going into developing the CNN architecture was extracting lower level features early in the model and quickly dwindling high-level features at the end in order to feed the final layer smaller inputs. This approach was successful although it was not met with other challenges. The model could not have too many layers and so the high-level features were extracted around the 4th or 5th layer. Again, with more RAM on the TX1 Jetson, the model could be improved dramatically. </p>

<h3><a id="user-content-cost-function-and-optimizer" class="anchor" href="#cost-function-and-optimizer" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cost Function and Optimizer</h3>

<p>Given the categorical nature of the labels, categorical entropy with a softmax function is the cost function used to optimized the model parameters. Adadelta is an effective method for adaptive learning rates (even with small batch sizes) and is used as the optimizer for the model. The Adam Optimizer was also used in the early attempts but Adadelta seemed to learn better overall.</p>

<h2><a id="user-content-results--evaluation" class="anchor" href="#results--evaluation" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Results &amp; Evaluation</h2>

<p>The evaluation labels are normalized multi-class binary vectors. If a song takes on a characterization, its label vector takes on a <code>1</code> in the respective index, otherwise <code>0</code>. The vector is then normalized to sum to 1. The prediction vector can be interpreted as a probability distribution vector with each entry giving the probability that a song exhibits a particular class label. Hence, the sum of the prediction vector is 1. The evaluation labels and prediction vectors are interpreted differently which makes it slightly difficult to assess the performance of the model. One is a vector of non-independent Bernoulli variables and the other is a probability distribution. Our metric requires that we measure the performance of a multi-classification, multi-label binary problem. There are multiple classes and every song can take on multiple labels. The labels themselves do not form any mutually exclusive set of classes.</p>

<p>One way to evaluate the model is to determine if the top <em>K</em> probabilities in the prediction vector contain the classes in the evaluation label (Top-K-categorical metric). This transforms our prediction vector into a vector of binary variables by setting the top <em>K</em> probabilities equal to 1 and the rest equal to 0 (and then normalizing). The image below compares the evaluation label with the prediction label over 188 class labels. Where the blue spikes aline vertically with the red spikes indicate that the model chose the correct characterization for the song. </p>

<p><a href="/dojochu/DLA-Interview/blob/master/images/top_k_comparison.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/top_k_comparison.png" alt="Top K Comparison" style="max-width:100%;"></a></p>

<p>We can use this new vector to evaluate our model. If <em>K</em> is arbitrarily chosen <code>(K = 10)</code>, the model succeeds if it contains the label classes in its top 10, otherwise the model fails. The all or none pass/fail criteria can be a bit harsh for model evaluation so there are variations of this metric such as the top <em>K</em> probabilities which contain at least a percentage % of the label classes. The chart below is an evaluation curve with different K and passing % cutoff. The more steep in the initial incline of the curve, the better the model.</p>

<p><a href="/dojochu/DLA-Interview/blob/master/images/top_k_curve.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/top_k_curve.png" alt="Evaluation Curve" style="max-width:100%;"></a></p>

<p>Based on the evaluation curve, the CNN model does poorly to characterize music. It only encompassed 60% of the class labels while looking at the top 50 probabilities of the prediction vector in order to achieve an 80% success rate on the testing data. It must look at the top 100 probabilties of the prediction vector to encompass 90% of the class labels in order to achieve the same 80% success rate.</p>

<p>The tables below displays a list of label classes that the model was able to best capture and the label classes the model did not capture very well. The CNN model does exceptionally well with instrumental music such as classical music with violin, guitar or piano; however, outside of opera, the model does not perform well when it comes to music with voices especially female voices.</p>

<p><em>Music Labels Best Captured</em></p>

<table><thead>
<tr>
<th>Category</th>
<th align="center">Captured</th>
<th align="center">Missed</th>
<th align="right">Rate</th>
</tr>
</thead><tbody>
<tr>
<td>violin</td>
<td align="center">57</td>
<td align="center">11</td>
<td align="right">83.8%</td>
</tr>
<tr>
<td>slow</td>
<td align="center">119</td>
<td align="center">14</td>
<td align="right">89.5%</td>
</tr>
<tr>
<td>rock</td>
<td align="center">93</td>
<td align="center">8</td>
<td align="right">92.1%</td>
</tr>
<tr>
<td>solo</td>
<td align="center">25</td>
<td align="center">1</td>
<td align="right">96.2%</td>
</tr>
<tr>
<td>piano</td>
<td align="center">68</td>
<td align="center">2</td>
<td align="right">97.1%</td>
</tr>
<tr>
<td>strings</td>
<td align="center">73</td>
<td align="center">1</td>
<td align="right">98.6%</td>
</tr>
<tr>
<td>classical</td>
<td align="center">178</td>
<td align="center">1</td>
<td align="right">99.4%</td>
</tr>
<tr>
<td>guitar</td>
<td align="center">178</td>
<td align="center">0</td>
<td align="right">100%</td>
</tr>
<tr>
<td>harpsichord</td>
<td align="center">8</td>
<td align="center">0</td>
<td align="right">100%</td>
</tr>
<tr>
<td>opera</td>
<td align="center">162</td>
<td align="center">0</td>
<td align="right">100%</td>
</tr>
</tbody></table>

<p><em>Music Labels Worst Captured</em></p>

<table><thead>
<tr>
<th>Category</th>
<th align="center">Captured</th>
<th align="center">Missed</th>
<th align="right">Rate</th>
</tr>
</thead><tbody>
<tr>
<td>synth</td>
<td align="center">16</td>
<td align="center">47</td>
<td align="right">25.1%</td>
</tr>
<tr>
<td>vocals</td>
<td align="center">2</td>
<td align="center">47</td>
<td align="right">4.1%</td>
</tr>
<tr>
<td>choral</td>
<td align="center">0</td>
<td align="center">48</td>
<td align="right">0%</td>
</tr>
<tr>
<td>quiet</td>
<td align="center">0</td>
<td align="center">55</td>
<td align="right">0%</td>
</tr>
<tr>
<td>woman</td>
<td align="center">0</td>
<td align="center">55</td>
<td align="right">0%</td>
</tr>
<tr>
<td>choir</td>
<td align="center">0</td>
<td align="center">59</td>
<td align="right">0%</td>
</tr>
<tr>
<td>singing</td>
<td align="center">5</td>
<td align="center">59</td>
<td align="right">7.8%</td>
</tr>
<tr>
<td>vocal</td>
<td align="center">12</td>
<td align="center">68</td>
<td align="right">15.0%</td>
</tr>
<tr>
<td>female</td>
<td align="center">4</td>
<td align="center">85</td>
<td align="right">4.5%</td>
</tr>
<tr>
<td>ambient</td>
<td align="center">0</td>
<td align="center">93</td>
<td align="right">0%</td>
</tr>
</tbody></table>

<h3><a id="user-content-spectrogram-samples" class="anchor" href="#spectrogram-samples" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Spectrogram Samples</h3>

<p>Below are some sample spectrograms from the model's best performing classes and the worst performing classes. There isn't any clear pattern seen with the human eye that would tell us how to classify the instrumental songs and the vocal songs. These are patterns that are learned in the hidden layers of the neural networks. </p>

<p><em>Violin Spectrogram Samples</em></p>

<p><a href="/dojochu/DLA-Interview/blob/master/images/violin.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/violin.png" alt="violin" style="max-width:100%;"></a></p>

<p><em>Guitar Spectrogram Samples</em>
<a href="/dojochu/DLA-Interview/blob/master/images/guitar.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/guitar.png" alt="guitar" style="max-width:100%;"></a></p>

<p><em>Piano Spectrogram Samples</em>
<a href="/dojochu/DLA-Interview/blob/master/images/piano.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/piano.png" alt="piano" style="max-width:100%;"></a></p>

<p><em>Ambient Spectrogram Samples</em>
<a href="/dojochu/DLA-Interview/blob/master/images/ambient.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/ambient.png" alt="ambient" style="max-width:100%;"></a></p>

<p><em>Vocal Spectrogram Samples</em>
<a href="/dojochu/DLA-Interview/blob/master/images/vocal.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/vocal.png" alt="vocal" style="max-width:100%;"></a></p>

<p><em>Female Spectrogram Samples</em>
<a href="/dojochu/DLA-Interview/blob/master/images/female.png" target="_blank"><img src="/dojochu/DLA-Interview/raw/master/images/female.png" alt="female" style="max-width:100%;"></a></p>

<p>The weakness of the model is due to a systemic error in the model and not likely due to the dataset. As you can see there are plenty of songs in the dataset that contain instruments and voice.</p>

<p><em>25 Most Common Labels</em></p>

<table><thead>
<tr>
<th>Category</th>
<th align="right">Count</th>
</tr>
</thead><tbody>
<tr>
<td>quiet</td>
<td align="right">1055</td>
</tr>
<tr>
<td>loud</td>
<td align="right">1086</td>
</tr>
<tr>
<td>harpsichord</td>
<td align="right">1093</td>
</tr>
<tr>
<td>no vocals</td>
<td align="right">1158</td>
</tr>
<tr>
<td>vocals</td>
<td align="right">1184</td>
</tr>
<tr>
<td>singing</td>
<td align="right">1211</td>
</tr>
<tr>
<td>male</td>
<td align="right">1279</td>
</tr>
<tr>
<td>opera</td>
<td align="right">1296</td>
</tr>
<tr>
<td>indian</td>
<td align="right">1395</td>
</tr>
<tr>
<td>female</td>
<td align="right">1474</td>
</tr>
<tr>
<td>synth</td>
<td align="right">1717</td>
</tr>
<tr>
<td>vocal</td>
<td align="right">1729</td>
</tr>
<tr>
<td>violin</td>
<td align="right">1826</td>
</tr>
<tr>
<td>beat</td>
<td align="right">1906</td>
</tr>
<tr>
<td>ambient</td>
<td align="right">1956</td>
</tr>
<tr>
<td>piano</td>
<td align="right">2056</td>
</tr>
<tr>
<td>fast</td>
<td align="right">2306</td>
</tr>
<tr>
<td>rock</td>
<td align="right">2371</td>
</tr>
<tr>
<td>electronic</td>
<td align="right">2519</td>
</tr>
<tr>
<td>drums</td>
<td align="right">2598</td>
</tr>
<tr>
<td>strings</td>
<td align="right">2729</td>
</tr>
<tr>
<td>techno</td>
<td align="right">2954</td>
</tr>
<tr>
<td>slow</td>
<td align="right">3547</td>
</tr>
<tr>
<td>classical</td>
<td align="right">4272</td>
</tr>
<tr>
<td>guitar</td>
<td align="right">4852</td>
</tr>
</tbody></table>

<h2><a id="user-content-conclusion-next-steps" class="anchor" href="#conclusion-next-steps" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion Next Steps</h2>

<p>There are many forks in the road at this point in the project. Each of them addressing different parts the problem. The model didn't perform as well as other machine learning music taggers that have used multivariate time series or autoregressive mxiture models. However, it was still impressive to see, with limiting resources, the model was still able to learn certain features such as instrument exceptionally well. There is certainly improvement that needs to be made to capture female voices in music. This is personally my first music tagging model and in further versions I would consider the following:</p>

<ol>
<li><p>Apply a different transformation on the audio data. Mel-Spectrogram is only one of many ways to visualize audio data. Rhythm pattern, beat pattern, and chromagrams are all different spectral and audio attributes that could be used as features in the model. Even with the Mel-Spectrogram, there are parameters such as sampling rate, number of bins, and Fourier transform window size that could be adjusted for better input features.</p></li>
<li><p>Apply a Recurrent Neural Network. The Convolutional Neural Network is a pass-forward method that does not take into account other information or stages of the overall neural network. Recurrent methods could be useful in feeding information from other areas of the network to determine the optimal weights and biases.</p></li>
<li><p>Customize the CNN to focus on the upper frequency of the spectrogram where it is known to capture high pitch voices. Because the model did poorly on identifying female voices in music, the added layers might improve the model's ability to extract particular features.</p></li>
<li><p>Using TensorBoard to visualize the feature space and weights produced by the training model to glean insight into the model training and identify patterns that could be exploited in further versions. </p></li>
<li><p>Try a different learner! Time series and autogression mixture models have shown promise!</p></li>
</ol>

<h2><a id="user-content-references" class="anchor" href="#references" aria-hidden="true"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h2>

<ul>
<li><a href="https://arxiv.org/pdf/1606.00298v1.pdf">Keunwoo Choi Automated Music Tagger</a></li>
<li><a href="https://arxiv.org/pdf/1609.04243.v3.pdf">CRNN for Music Genre Classification</a></li>
<li><a href="https://colah.github.io">Colah's Blog</a></li>
<li><a href="http://www.keras.io">Keras.io</a> - The deep learning framework and tools used</li>
<li><a href="https://librosa.github.io/librosa">Librosa</a></li>
<li><a href="https://wiki.python.org/miooin/PythonInMusic">Python In Music</a></li>
<li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> </li>
<li><a href="https://cs231n.github.io/neural-networks-3">Stanford CS231 Convolutional Neural Networks</a></li>
<li><a href="https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3">VGG16 Model for Keras</a></li>
<li><a href="https://www.cs.cmu.edu/%7Egtzan/work/pubs/thesis02gtzan.pdf">Audio Representation Paper</a></li>
</ul>
</article>
  </div>

</div>

<button type="button" data-facebox="#jump-to-line" data-facebox-class="linejump" data-hotkey="l" class="d-none">Jump to Line</button>
<div id="jump-to-line" style="display:none">
  <!-- '"` --><!-- </textarea></xmp> --></option></form><form accept-charset="UTF-8" action="" class="js-jump-to-line-form" method="get"><div style="margin:0;padding:0;display:inline"><input name="utf8" type="hidden" value="&#x2713;" /></div>
    <input class="form-control linejump-input js-jump-to-line-field" type="text" placeholder="Jump to line&hellip;" aria-label="Jump to line" autofocus>
    <button type="submit" class="btn">Go</button>
</form></div>

  </div>
  <div class="modal-backdrop js-touch-events"></div>
</div>


    </div>
  </div>

    </div>

        <div class="container site-footer-container">
  <div class="site-footer" role="contentinfo">
    <ul class="site-footer-links float-right">
        <li><a href="https://github.com/contact" data-ga-click="Footer, go to contact, text:contact">Contact GitHub</a></li>
      <li><a href="https://developer.github.com" data-ga-click="Footer, go to api, text:api">API</a></li>
      <li><a href="https://training.github.com" data-ga-click="Footer, go to training, text:training">Training</a></li>
      <li><a href="https://shop.github.com" data-ga-click="Footer, go to shop, text:shop">Shop</a></li>
        <li><a href="https://github.com/blog" data-ga-click="Footer, go to blog, text:blog">Blog</a></li>
        <li><a href="https://github.com/about" data-ga-click="Footer, go to about, text:about">About</a></li>

    </ul>

    <a href="https://github.com" aria-label="Homepage" class="site-footer-mark" title="GitHub">
      <svg aria-hidden="true" class="octicon octicon-mark-github" height="24" version="1.1" viewBox="0 0 16 16" width="24"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>
    <ul class="site-footer-links">
      <li>&copy; 2017 <span title="0.08917s from github-fe156-cp1-prd.iad.github.net">GitHub</span>, Inc.</li>
        <li><a href="https://github.com/site/terms" data-ga-click="Footer, go to terms, text:terms">Terms</a></li>
        <li><a href="https://github.com/site/privacy" data-ga-click="Footer, go to privacy, text:privacy">Privacy</a></li>
        <li><a href="https://github.com/security" data-ga-click="Footer, go to security, text:security">Security</a></li>
        <li><a href="https://status.github.com/" data-ga-click="Footer, go to status, text:status">Status</a></li>
        <li><a href="https://help.github.com" data-ga-click="Footer, go to help, text:help">Help</a></li>
    </ul>
  </div>
</div>



    

    <div id="ajax-error-message" class="ajax-error-message flash flash-error">
      <svg aria-hidden="true" class="octicon octicon-alert" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M8.865 1.52c-.18-.31-.51-.5-.87-.5s-.69.19-.87.5L.275 13.5c-.18.31-.18.69 0 1 .19.31.52.5.87.5h13.7c.36 0 .69-.19.86-.5.17-.31.18-.69.01-1L8.865 1.52zM8.995 13h-2v-2h2v2zm0-3h-2V6h2v4z"/></svg>
      <button type="button" class="flash-close js-flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
        <svg aria-hidden="true" class="octicon octicon-x" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
      </button>
      You can't perform that action at this time.
    </div>


      
      <script crossorigin="anonymous" integrity="sha256-0j4y5IIRK6Xj6pvY3H5VVoARanTgAnRqyR9BpOWHWps=" src="https://assets-cdn.github.com/assets/frameworks-d23e32e482112ba5e3ea9bd8dc7e555680116a74e002746ac91f41a4e5875a9b.js"></script>
      <script async="async" crossorigin="anonymous" integrity="sha256-WzCjnh2dl6edSil6o/9nv1b6t0gCUkZNsbboDbqxBpA=" src="https://assets-cdn.github.com/assets/github-5b30a39e1d9d97a79d4a297aa3ff67bf56fab7480252464db1b6e80dbab10690.js"></script>
      
      
      
      
    <div class="js-stale-session-flash stale-session-flash flash flash-warn flash-banner d-none">
      <svg aria-hidden="true" class="octicon octicon-alert" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M8.865 1.52c-.18-.31-.51-.5-.87-.5s-.69.19-.87.5L.275 13.5c-.18.31-.18.69 0 1 .19.31.52.5.87.5h13.7c.36 0 .69-.19.86-.5.17-.31.18-.69.01-1L8.865 1.52zM8.995 13h-2v-2h2v2zm0-3h-2V6h2v4z"/></svg>
      <span class="signed-in-tab-flash">You signed in with another tab or window. <a href="">Reload</a> to refresh your session.</span>
      <span class="signed-out-tab-flash">You signed out in another tab or window. <a href="">Reload</a> to refresh your session.</span>
    </div>
    <div class="facebox" id="facebox" style="display:none;">
  <div class="facebox-popup">
    <div class="facebox-content" role="dialog" aria-labelledby="facebox-header" aria-describedby="facebox-description">
    </div>
    <button type="button" class="facebox-close js-facebox-close" aria-label="Close modal">
      <svg aria-hidden="true" class="octicon octicon-x" height="16" version="1.1" viewBox="0 0 12 16" width="12"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48z"/></svg>
    </button>
  </div>
</div>

  </body>
</html>

